{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Data Wrangling With Screaming Frog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "\n",
    "- To learn how to automate the command line Screaming Frog commands with Python\n",
    "- To learn how to wrangle 5 .csv files from Screaming Frog with Pandas\n",
    "- To learn how to push the data into a BigQuery table\n",
    "- To learn how to connect your BigQuery table to Google Data Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last tutorial, you learned how to [easily automate Screaming Frog on the command line for either Mac or Windows.](https://sempioneer.com/python-for-seo/screaming-frog-automation/).\n",
    "\n",
    "In this section we'll be focusing on automating the previous terminal commands with Python.\n",
    "\n",
    "Then we'll wrangle the .csv data into Pandas, push it into [BigQuery](https://cloud.google.com/bigquery) and finally view it in [Google Data Studio.](https://datastudio.google.com/u/0/navigation/reporting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "    \n",
    "- https://docs.python.org/3/library/subprocess.html\n",
    "- https://www.jstorimer.com/blogs/workingwithcode/7766119-when-to-use-stderr-instead-of-stdout\n",
    "- https://pandas.pydata.org/\n",
    "- https://www.vervesearch.com/blog/screaming-frog-google-compute-cloud-automatically-crawl-an-entire-industry-fast/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Scripts To Refactor:</strong>\n",
    "- https://www.vervesearch.com/screaming-frog-files/scream.py\n",
    "- https://www.vervesearch.com/screaming-frog-files/auto-ssh.py\n",
    "- https://raw.githubusercontent.com/skywind3000/terminal/master/terminal.py\n",
    "- https://www.vervesearch.com/blog/compare-screaming-frog-crawl-files/\n",
    "- https://github.com/skywind3000/terminal/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> To Research: </strong>\n",
    "    \n",
    "- What does os.system do? (This has been replaced with the subprocess module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.7/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/jamesaphoenix/.local/lib/python3.7/site-packages (from pandas) (2.8.0)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.7/site-packages (from pandas) (2019.3)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/anaconda3/lib/python3.7/site-packages (from pandas) (1.18.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/jamesaphoenix/.local/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.11.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Run The Command Line In Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll be using linux commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args='ls', returncode=0, stdout=b'data-wrangling-screaming-frog.ipynb\\n', stderr=b'')\n"
     ]
    }
   ],
   "source": [
    "process = subprocess.run(\"ls\", shell=True, check=True, capture_output=True)\n",
    "print(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the return code of the subprocess: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"This is the return code of the subprocess: {process.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Typically a <strong> returncode 0 means that the command run successfully. </strong>\n",
    "- Also notice how the output of the command is pushed into stdout (standard output), stderr (standard errror)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Run The Screaming Frog Command Line Scripts With Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract our username, website, output location and Screaming Frog application and put them into variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jamesaphoenix/Desktop/Imran_And_James/Python_For_SEO/11_data_wrangling_screaming_frog\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'jamesaphoneix'\n",
    "website = 'https://phoenixandpartners.co.uk/'\n",
    "output_location = '/users/jamesaphoenix/desktop'\n",
    "screaming_frog_app = '/Applications/Screaming\\ Frog\\ SEO\\ Spider.app/Contents/MacOS/ScreamingFrogSEOSpiderLauncher'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username: jamesaphoneix '\n",
      "Website: https://phoenixandpartners.co.uk/ \n",
      "OutputLocation: --output-folder /users/jamesaphoneix/desktop \n",
      "ScreamingFrogLocation: /Applications/Screaming\\ Frog\\ SEO\\ Spider.app/Contents/MacOS/ScreamingFrogSEOSpiderLauncher\n"
     ]
    }
   ],
   "source": [
    "print(\"Username:\",username, \"'\\nWebsite:\",website, '\\nOutputLocation:', output_location,\n",
    "     \"\\nScreamingFrogLocation:\",screaming_frog_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a couple of Screaming Frog string commands that we'll push into subprocess commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "screaming_frog_open = \"/Applications/Screaming Frog SEO Spider.app/Contents/MacOS/ScreamingFrogSEOSpiderLauncher\"\n",
    "screaming_frog_crawl=f'{screaming_frog_app} --headless --save-crawl --output-folder {output_location} --timestamped-output --crawl phoenixandpartners.co.uk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Applications/Screaming\\\\ Frog\\\\ SEO\\\\ Spider.app/Contents/MacOS/ScreamingFrogSEOSpiderLauncher --headless --save-crawl --output-folder /users/jamesaphoenix/desktop --timestamped-output --crawl phoenixandpartners.co.uk'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screaming_frog_crawl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also notice, how we've used an f string for the screaming_frog_crawl variable, which means:\n",
    "\n",
    "- jamesaphoenix will be passed into this text string instead of {username}.\n",
    "- https://phoenixandpartners.co.uk/ will be passed into this text string instead of {website}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Applications/Screaming\\ Frog\\ SEO\\ Spider.app/Contents/MacOS/ScreamingFrogSEOSpiderLauncher --headless --save-crawl --output-folder /users/jamesaphoenix/desktop --timestamped-output --crawl phoenixandpartners.co.uk\n"
     ]
    }
   ],
   "source": [
    "print(screaming_frog_crawl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run them one by one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sf = subprocess.run(screaming_frog_open)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command will hopefully open scremaing frog, also the subprocess will keep running until we close the window.\n",
    "\n",
    "So close screaming frog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args='/Applications/Screaming Frog SEO Spider.app/Contents/MacOS/ScreamingFrogSEOSpiderLauncher', returncode=0)\n"
     ]
    }
   ],
   "source": [
    "print(open_sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the return code was 0!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "screaming_frog=subprocess.run(screaming_frog_crawl, \n",
    "               shell=True, \n",
    "               capture_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Applications/Screaming\\\\ Frog\\\\ SEO\\\\ Spider.app/Contents/MacOS/ScreamingFrogSEOSpiderLauncher --headless --save-crawl --output-folder /users/jamesaphoenix/desktop --timestamped-output --crawl phoenixandpartners.co.uk'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screaming_frog_crawl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://sempioneer.com/wp-content/uploads/2020/06/screaming-frog-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How To Find The Outputted Folder Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as saving the crawl, we can parse the standard output pipe (stdout) and obtain the name of the timestamped folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'args',\n",
       " 'check_returncode',\n",
       " 'returncode',\n",
       " 'stderr',\n",
       " 'stdout']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(screaming_frog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can decode the stdout which will convert all of the console messages into a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-25\n"
     ]
    }
   ],
   "source": [
    "text = screaming_frog.stdout.decode('utf-8')\n",
    "print(text[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's search the date timestamp:\n",
    "\n",
    "- after this: <strong> Output directory: </strong>\n",
    "- before this: <strong> \\n </strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://sempioneer.com/wp-content/uploads/2020/06/output-directory.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the timestamped output folder: /users/jamesaphoenix/desktop/2020.06.25.15.01.49\n"
     ]
    }
   ],
   "source": [
    "timestamp = re.findall('(?<=Output directory:)(.*?)(?=\\n)', \n",
    "                       str(text))\n",
    "\n",
    "correct_folder = timestamp[0].strip()\n",
    "print(f\"This is the timestamped output folder: {correct_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check what folders are in our current working directory with:\n",
    "\n",
    "~~~\n",
    "\n",
    "os.listdir()\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Music',\n",
       " 'Screaming Frog - Data Manipulation.ipynb',\n",
       " 'ngrok',\n",
       " '2020.06.25.15.01.49',\n",
       " '.DS_Store',\n",
       " '.localized',\n",
       " 'config',\n",
       " 'Coding_Marketing_Projects',\n",
       " 'Google_cloud-sdk',\n",
       " 'screaming-frog-remotedesktop-image.vmdk',\n",
       " 'Screenshot 2020-06-25 at 15.07.17.png',\n",
       " 'Extracting Schema At Bulk.ipynb',\n",
       " 'Scripts_and_keys',\n",
       " 'YouTube SEO.jpg',\n",
       " 'Data_Science_Resources',\n",
       " 'Screenshot 2020-06-25 at 15.07.17 (2).png',\n",
       " 'Marketing',\n",
       " 'Sort Through These',\n",
       " 'Atom.app',\n",
       " 'Math Textbooks',\n",
       " '.ipynb_checkpoints',\n",
       " 'Client_Projects',\n",
       " 'Imran_And_James',\n",
       " 'General_Assembly',\n",
       " 'layered_architecture.png',\n",
       " 'Postman.app',\n",
       " 'message.png']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/Users/jamesaphoenix/Desktop') # This changes the directory into the desktop\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://sempioneer.com/wp-content/uploads/2020/06/output-of-directory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to capture the relevant folder would be to:\n",
    "    \n",
    "1. Get todays date.\n",
    "2. Only return folders that include todays date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020.06.25\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "todays_date = now.strftime(\"%Y.%m.%d\")\n",
    "print(todays_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020.06.25.15.01.49']\n"
     ]
    }
   ],
   "source": [
    "screaming_frog_folders = [file for file in os.listdir() if todays_date in file]\n",
    "print(screaming_frog_folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhancing Our Screaming Frog CLI Automation With Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the subprocess and string command is a better improvement then having to load up terminal and manually enter in the commands.\n",
    "\n",
    "But let's take it a step further and create a Python Class called 🐸 <strong> ScreamingFrogAnalyser </strong> 🐸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>To Do:</strong>\n",
    "    \n",
    "- Runs a standard screamig frog crawl\n",
    "- Allows a specific folder to be an output folder\n",
    "    \n",
    "- Add the ability to:\n",
    "    - Add reports\n",
    "    - Bulk export\n",
    "    \n",
    "- Parsing for the newly created output directory\n",
    "- Option to run ScreamingFrog Headless or Not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/jamesaphoenix/desktop'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screaming_frog_crawl=f'{screaming_frog_app} --headless --save-crawl --output-folder {output_location} --timestamped-output --crawl phoenixandpartners.co.uk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTS TO CREATE\n",
    "\n",
    "- DIFFERENT RESULTS FOR CHECK FOR REPORTS\n",
    "- DIFFERENT OPERATING SYSTEMS\n",
    "- ADD IN CHECKING FOR ALL OF THE REPORT NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Having Fun With Python Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupportedPlatformError(Exception):\n",
    "    def __init__(self, message, errors):\n",
    "\n",
    "        # Call the base class constructor with the parameters it needs\n",
    "        super().__init__(message)\n",
    "\n",
    "        # Now for your custom code...\n",
    "        self.errors = errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationError(Exception):\n",
    "    def __init__(self, message, errors):\n",
    "\n",
    "        # Call the base class constructor with the parameters it needs\n",
    "        super().__init__(message)\n",
    "\n",
    "        # Now for your custom code...\n",
    "        self.errors = errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScreamingFrogAnalyser(object):\n",
    "    def __init__(self, website_urls,\n",
    "                 user_name,\n",
    "                 outputfolder='',\n",
    "                 export_tabs=False,\n",
    "                 export_reports=False,\n",
    "                 export_bulk_exports=False):\n",
    "        \n",
    "        self._website_urls = website_urls\n",
    "        self._user_name = user_name\n",
    "        self._output_folder = '--output-folder ' + outputfolder\n",
    "        self._export_tabs = export_tabs\n",
    "        self._export_reports = export_reports\n",
    "        self.export_bulk_exports = export_bulk_exports\n",
    "        \n",
    "        # This will populate with a list of folders that Screaming Frog Creates via --timestamped folder:\n",
    "        self._sf_folders = []\n",
    "        \n",
    "        if self._output_folder == '':\n",
    "            raise ValidationError('You must choose a valid output folder for your Screaming Frog Crawls',\n",
    "                                 'outputfolder=\"\"')\n",
    "            \n",
    "        # Creating the command based upon the Operating System:\n",
    "        self._create_command()\n",
    "        self._command_updater()\n",
    "    \n",
    "    def _create_command(self):\n",
    "        if platform == \"linux\" or platform == \"linux2\":\n",
    "            # Linux\n",
    "            self._sf_command = 'screamingfrogspider --headless --save-crawl'\n",
    "        elif platform == \"darwin\":\n",
    "            # OS X\n",
    "            self._sf_command = '/Applications/Screaming\\ Frog\\ SEO\\ Spider.app/Contents/MacOS/ScreamingFrogSEOSpiderLauncher --headless --save-crawl'\n",
    "        elif platform == \"win32\":\n",
    "            # Windows...\n",
    "            raise UnsupportedPlatformError(\"Windows Is Currently Not Supported\", 'Please stop using windows!')\n",
    "            \n",
    "    def _add_reports(self):\n",
    "        for _, argument in zip([self._export_tabs, self._export_reports, self.export_bulk_exports],\n",
    "                    ['--export-tabs', '--save-report', '--bulk-export']):\n",
    "            if _ is not False:\n",
    "                self.sf_command = self.sf_command + f' {argument} \"{_}\"'\n",
    "            else:\n",
    "                # This will just save the generic .seospider crawl\n",
    "                pass\n",
    "    \n",
    "    def _parse_subprocess_text(self, subprocess_text):\n",
    "        directory = re.findall('(?<=Output directory:)(.*?)(?=\\n)', \n",
    "                       str(subprocess_text.decode('utf-8')))\n",
    "        return directory[0].strip()\n",
    "\n",
    "    def _command_updater(self):\n",
    "        self.sf_command = self._sf_command + ' ' + self._output_folder + ' --timestamped-output'\n",
    "        print(f\"Please make sure that the {self._output_folder} is a valid destination! \\n\")\n",
    "        self._add_reports()\n",
    "        print(self.sf_command)\n",
    "    \n",
    "    # Execution Functions\n",
    "    def run_screaming_headless_frog(self, website):\n",
    "        final_command = self.sf_command + ' --crawl ' + website\n",
    "        screaming_frog=subprocess.run(final_command, \n",
    "        shell=True, \n",
    "        capture_output=True)\n",
    "        return screaming_frog\n",
    "        \n",
    "    # Run Multiple Websites:\n",
    "    def run_crawls(self):\n",
    "        for website in self._website_urls:\n",
    "            # 1. Crawl the website: \n",
    "            output = self.run_screaming_headless_frog(website)\n",
    "            # 2. Store the crawled files:\n",
    "            resp = self._parse_subprocess_text(output.stdout)\n",
    "            if isinstance(resp, str):\n",
    "                self._sf_folders.append(resp)\n",
    "            else:\n",
    "                raise ValidationError('No folder was created, check your output folder and export settings', 'Incorrect Response')\n",
    "            print('\\n' + '----' + '\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSV_Parser():\n",
    "    def __init__(self, file_paths):\n",
    "        pass\n",
    "    \n",
    "    def group_multiple_csv_files(self):\n",
    "        pass    \n",
    "    \n",
    "    def merge_multiple_csv_files(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigQuery():\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make sure that the --output-folder /users/jamesaphoenix/desktop is a valid destination! \n",
      "\n",
      "/Applications/Screaming\\ Frog\\ SEO\\ Spider.app/Contents/MacOS/ScreamingFrogSEOSpiderLauncher --headless --save-crawl --output-folder /users/jamesaphoenix/desktop --timestamped-output --export-tabs \"Response Codes:Client Error (4xx)\"\n"
     ]
    }
   ],
   "source": [
    "sf = ScreamingFrogAnalyser(user_name='jamesaphoenix',website_urls=['https://phoenixandpartners.co.uk/'],\n",
    "                           outputfolder='/users/jamesaphoenix/desktop', \n",
    "                           export_tabs='Response Codes:Client Error (4xx)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Applications/Screaming\\ Frog\\ SEO\\ Spider.app/Contents/MacOS/ScreamingFrogSEOSpiderLauncher --headless --save-crawl []\n"
     ]
    }
   ],
   "source": [
    "print(sf._sf_command, sf._sf_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sf.run_crawls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/users/jamesaphoenix/desktop/2020.06.25.23.09.50']"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf._sf_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Working Here On Exporting All Of The Files:\n",
    "outputfolder = '/users/jamesaphoenix/desktop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['2020.06.25.23.10.31', '2020.06.25.23.11.30', '2020.06.25.23.09.50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_directories = [outputfolder + '/' + folder for folder in folders]\n",
    "correct_files = [directory + '/' + files for directory in correct_directories\n",
    "                 for files in os.listdir(path=directory)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Working On Grouping Files\n",
    "file_dict = {}\n",
    "\n",
    "for file in correct_files:\n",
    "    split_file = file.split('/')\n",
    "    name = split_file[-1]\n",
    "    if split_file[-1] not in file_dict.keys():\n",
    "        file_dict[str(name)] = [file]\n",
    "    else:\n",
    "        file_dict[str(name)].append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The Screaming Frog CSV Data In Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO:\n",
    "- WE WILL NEED TO ADD THE DOMAIN BELOW!\n",
    "- THE CODE BELOW NEEDS REFACTORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Working On Concatenating Files\n",
    "data_dict = {}\n",
    "\n",
    "for key, values in file_dict.items():\n",
    "    # 1. Temporary Dataframe\n",
    "    df = pd.DataFrame()\n",
    "    # 2. Munge all of the data:\n",
    "    for value in values:\n",
    "        if value.endswith(('.csv')):\n",
    "            name = value.split('/')[-1]\n",
    "            if name not in data_dict.keys():\n",
    "                data_dict[name] = ''\n",
    "            temp_df = pd.read_csv(value)\n",
    "            df = df.append(temp_df)\n",
    "            data_dict[name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Content</th>\n",
       "      <th>Status Code</th>\n",
       "      <th>Status</th>\n",
       "      <th>Indexability</th>\n",
       "      <th>Indexability Status</th>\n",
       "      <th>Inlinks</th>\n",
       "      <th>Response Time</th>\n",
       "      <th>Redirect URL</th>\n",
       "      <th>Redirect Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://phoenixandpartners.co.uk/wp-content/up...</td>\n",
       "      <td>text/html; charset=UTF-8</td>\n",
       "      <td>404</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Non-Indexable</td>\n",
       "      <td>Client Error</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://phoenixandpartners.co.uk/wp-content/up...</td>\n",
       "      <td>text/html; charset=UTF-8</td>\n",
       "      <td>404</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Non-Indexable</td>\n",
       "      <td>Client Error</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.bankrate.com/finance/real-estate/r...</td>\n",
       "      <td>text/html; charset=UTF-8</td>\n",
       "      <td>410</td>\n",
       "      <td>Gone</td>\n",
       "      <td>Non-Indexable</td>\n",
       "      <td>Client Error</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://metro.co.uk/2018/03/15/5-people-share-...</td>\n",
       "      <td>text/html</td>\n",
       "      <td>429</td>\n",
       "      <td>Too Many Requests</td>\n",
       "      <td>Non-Indexable</td>\n",
       "      <td>Client Error</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.simplelandlordsinsurance.com/emerg...</td>\n",
       "      <td>text/html; charset=utf-8</td>\n",
       "      <td>404</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Non-Indexable</td>\n",
       "      <td>Client Error</td>\n",
       "      <td>1</td>\n",
       "      <td>0.409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://phoenixandpartners.co.uk/wp-content/up...</td>\n",
       "      <td>text/html; charset=UTF-8</td>\n",
       "      <td>404</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Non-Indexable</td>\n",
       "      <td>Client Error</td>\n",
       "      <td>0</td>\n",
       "      <td>0.293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://phoenixandpartners.co.uk/wp-content/up...</td>\n",
       "      <td>text/html; charset=UTF-8</td>\n",
       "      <td>404</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Non-Indexable</td>\n",
       "      <td>Client Error</td>\n",
       "      <td>0</td>\n",
       "      <td>0.306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.bankrate.com/finance/real-estate/r...</td>\n",
       "      <td>text/html; charset=UTF-8</td>\n",
       "      <td>410</td>\n",
       "      <td>Gone</td>\n",
       "      <td>Non-Indexable</td>\n",
       "      <td>Client Error</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://metro.co.uk/2018/03/15/5-people-share-...</td>\n",
       "      <td>text/html</td>\n",
       "      <td>429</td>\n",
       "      <td>Too Many Requests</td>\n",
       "      <td>Non-Indexable</td>\n",
       "      <td>Client Error</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.simplelandlordsinsurance.com/emerg...</td>\n",
       "      <td>text/html; charset=utf-8</td>\n",
       "      <td>404</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Non-Indexable</td>\n",
       "      <td>Client Error</td>\n",
       "      <td>1</td>\n",
       "      <td>0.069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://phoenixandpartners.co.uk/wp-content/up...</td>\n",
       "      <td>text/html; charset=UTF-8</td>\n",
       "      <td>404</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Non-Indexable</td>\n",
       "      <td>Client Error</td>\n",
       "      <td>0</td>\n",
       "      <td>0.314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://phoenixandpartners.co.uk/wp-content/up...</td>\n",
       "      <td>text/html; charset=UTF-8</td>\n",
       "      <td>404</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Non-Indexable</td>\n",
       "      <td>Client Error</td>\n",
       "      <td>0</td>\n",
       "      <td>0.322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.bankrate.com/finance/real-estate/r...</td>\n",
       "      <td>text/html; charset=UTF-8</td>\n",
       "      <td>410</td>\n",
       "      <td>Gone</td>\n",
       "      <td>Non-Indexable</td>\n",
       "      <td>Client Error</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://metro.co.uk/2018/03/15/5-people-share-...</td>\n",
       "      <td>text/html</td>\n",
       "      <td>429</td>\n",
       "      <td>Too Many Requests</td>\n",
       "      <td>Non-Indexable</td>\n",
       "      <td>Client Error</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.simplelandlordsinsurance.com/emerg...</td>\n",
       "      <td>text/html; charset=utf-8</td>\n",
       "      <td>404</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Non-Indexable</td>\n",
       "      <td>Client Error</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Address  \\\n",
       "0  https://phoenixandpartners.co.uk/wp-content/up...   \n",
       "1  https://phoenixandpartners.co.uk/wp-content/up...   \n",
       "2  https://www.bankrate.com/finance/real-estate/r...   \n",
       "3  https://metro.co.uk/2018/03/15/5-people-share-...   \n",
       "4  https://www.simplelandlordsinsurance.com/emerg...   \n",
       "0  https://phoenixandpartners.co.uk/wp-content/up...   \n",
       "1  https://phoenixandpartners.co.uk/wp-content/up...   \n",
       "2  https://www.bankrate.com/finance/real-estate/r...   \n",
       "3  https://metro.co.uk/2018/03/15/5-people-share-...   \n",
       "4  https://www.simplelandlordsinsurance.com/emerg...   \n",
       "0  https://phoenixandpartners.co.uk/wp-content/up...   \n",
       "1  https://phoenixandpartners.co.uk/wp-content/up...   \n",
       "2  https://www.bankrate.com/finance/real-estate/r...   \n",
       "3  https://metro.co.uk/2018/03/15/5-people-share-...   \n",
       "4  https://www.simplelandlordsinsurance.com/emerg...   \n",
       "\n",
       "                    Content  Status Code             Status   Indexability  \\\n",
       "0  text/html; charset=UTF-8          404          Not Found  Non-Indexable   \n",
       "1  text/html; charset=UTF-8          404          Not Found  Non-Indexable   \n",
       "2  text/html; charset=UTF-8          410               Gone  Non-Indexable   \n",
       "3                 text/html          429  Too Many Requests  Non-Indexable   \n",
       "4  text/html; charset=utf-8          404          Not Found  Non-Indexable   \n",
       "0  text/html; charset=UTF-8          404          Not Found  Non-Indexable   \n",
       "1  text/html; charset=UTF-8          404          Not Found  Non-Indexable   \n",
       "2  text/html; charset=UTF-8          410               Gone  Non-Indexable   \n",
       "3                 text/html          429  Too Many Requests  Non-Indexable   \n",
       "4  text/html; charset=utf-8          404          Not Found  Non-Indexable   \n",
       "0  text/html; charset=UTF-8          404          Not Found  Non-Indexable   \n",
       "1  text/html; charset=UTF-8          404          Not Found  Non-Indexable   \n",
       "2  text/html; charset=UTF-8          410               Gone  Non-Indexable   \n",
       "3                 text/html          429  Too Many Requests  Non-Indexable   \n",
       "4  text/html; charset=utf-8          404          Not Found  Non-Indexable   \n",
       "\n",
       "  Indexability Status  Inlinks  Response Time  Redirect URL  Redirect Type  \n",
       "0        Client Error        0          0.300           NaN            NaN  \n",
       "1        Client Error        0          0.337           NaN            NaN  \n",
       "2        Client Error        1          0.010           NaN            NaN  \n",
       "3        Client Error        1          0.012           NaN            NaN  \n",
       "4        Client Error        1          0.409           NaN            NaN  \n",
       "0        Client Error        0          0.293           NaN            NaN  \n",
       "1        Client Error        0          0.306           NaN            NaN  \n",
       "2        Client Error        1          0.013           NaN            NaN  \n",
       "3        Client Error        1          0.010           NaN            NaN  \n",
       "4        Client Error        1          0.069           NaN            NaN  \n",
       "0        Client Error        0          0.314           NaN            NaN  \n",
       "1        Client Error        0          0.322           NaN            NaN  \n",
       "2        Client Error        1          0.012           NaN            NaN  \n",
       "3        Client Error        1          0.009           NaN            NaN  \n",
       "4        Client Error        1          0.056           NaN            NaN  "
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['response_codes_client_error_(4xx).csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling All Of The CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigQuery Setup\n",
    "\n",
    "- API Creation\n",
    "- Table Creation\n",
    "- Service Account Key Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushing The Data To BigQuery\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting The BigQuery Table to Google Data Studio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
